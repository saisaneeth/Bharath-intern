# Import necessary libraries
import pandas as pd
from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate, train_test_split
from surprise.accuracy import rmse

# Load dataset
# Assuming you have a CSV file named 'ratings.csv' with columns: userId, movieId, rating
ratings = pd.read_csv('ratings.csv')

# Define the Reader object
reader = Reader(rating_scale=(1, 5))

# Load the data into Surprise Dataset format
data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Split the data into training and testing sets
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# Use Singular Value Decomposition (SVD) algorithm for collaborative filtering
algo = SVD()

# Train the model
algo.fit(trainset)

# Make predictions on the test data
predictions = algo.test(testset)

# Calculate RMSE (Root Mean Squared Error)
accuracy = rmse(predictions)
print("RMSE:", accuracy)

# Example: Get top N recommendations for a given user
def get_top_n_recommendations(predictions, n=5):
    top_n = {}
    for uid, iid, true_r, est, _ in predictions:
        if uid not in top_n:
            top_n[uid] = []
        top_n[uid].append((iid, est))

    for uid, user_ratings in top_n.items():
        user_ratings.sort(key=lambda x: x[1], reverse=True)
        top_n[uid] = user_ratings[:n]
    
    return top_n

# Get top 5 recommendations for user with userId 1
top_n_recommendations = get_top_n_recommendations(predictions)
print("Top 5 Recommendations for User 1:")
for movie_id, estimated_rating in top_n_recommendations[1]:
    movie_title = ratings[ratings['movieId'] == movie_id]['title'].iloc[0]  # Assuming you have a column 'title' in your dataset
    print(f"Movie: {movie_title}, Estimated Rating: {estimated_rating}")
